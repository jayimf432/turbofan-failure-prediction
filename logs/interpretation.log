2026-02-14 21:02:08,056 - __main__ - INFO - Loading model and data...
2026-02-14 21:02:08,101 - __main__ - INFO - Loaded resources. Output directory: /Users/jay-mac/Documents/End to End ML Projects/prediction project/outputs/interpretability
2026-02-14 21:02:08,101 - __main__ - INFO - Calculating SHAP values...
2026-02-14 21:02:10,991 - __main__ - INFO - SHAP values calculated.
2026-02-14 21:02:10,991 - __main__ - INFO - Generating global importance plot...
2026-02-14 21:02:11,260 - __main__ - INFO - Generating local explanations for 5 samples...
2026-02-14 21:02:11,270 - __main__ - ERROR - Interpretation failed: The waterfall plot can currently only plot a single explanation, but a matrix of explanations (shape (50, 2)) was passed! Perhaps try `shap.plots.waterfall(shap_values[0])` or for multi-output models, try `shap.plots.waterfall(shap_values[0, 0])`.
2026-02-14 21:02:40,672 - __main__ - INFO - Loading model and data...
2026-02-14 21:02:40,715 - __main__ - INFO - Loaded resources. Output directory: /Users/jay-mac/Documents/End to End ML Projects/prediction project/outputs/interpretability
2026-02-14 21:02:40,715 - __main__ - INFO - Calculating SHAP values...
2026-02-14 21:02:43,653 - __main__ - INFO - SHAP values calculated.
2026-02-14 21:02:43,653 - __main__ - INFO - Generating global importance plot...
2026-02-14 21:02:43,935 - __main__ - INFO - Generating local explanations for 5 samples...
2026-02-14 21:02:43,947 - __main__ - ERROR - Interpretation failed: The waterfall plot can currently only plot a single explanation, but a matrix of explanations (shape (50, 2)) was passed! Perhaps try `shap.plots.waterfall(shap_values[0])` or for multi-output models, try `shap.plots.waterfall(shap_values[0, 0])`.
2026-02-14 21:04:06,259 - __main__ - INFO - Loading model and data...
2026-02-14 21:04:06,307 - __main__ - INFO - Loaded resources. Output directory: /Users/jay-mac/Documents/End to End ML Projects/prediction project/outputs/interpretability
2026-02-14 21:04:06,307 - __main__ - INFO - Calculating SHAP values...
2026-02-14 21:04:09,221 - __main__ - INFO - SHAP values type: <class 'numpy.ndarray'>
2026-02-14 21:04:09,221 - __main__ - INFO - SHAP values shape: (500, 50, 2)
2026-02-14 21:04:09,221 - __main__ - INFO - SHAP values calculated.
2026-02-14 21:04:09,221 - __main__ - INFO - Generating global importance plot...
2026-02-14 21:04:09,606 - __main__ - INFO - Generating local explanations for 5 samples...
2026-02-14 21:04:10,181 - __main__ - INFO - Generating dependence plots...
2026-02-14 21:04:10,652 - __main__ - INFO - Calculating SHAP interaction values...
2026-02-14 21:04:35,448 - __main__ - WARNING - Could not calculate interactions: operands could not be broadcast together with shapes (50,50,2,50,2) (50,) 
2026-02-14 21:04:35,448 - __main__ - INFO - Testing single prediction explanation...
2026-02-14 21:04:35,469 - __main__ - ERROR - Interpretation failed: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
2026-02-14 21:04:57,208 - __main__ - INFO - Loading model and data...
2026-02-14 21:04:57,255 - __main__ - INFO - Loaded resources. Output directory: /Users/jay-mac/Documents/End to End ML Projects/prediction project/outputs/interpretability
2026-02-14 21:04:57,255 - __main__ - INFO - Calculating SHAP values...
2026-02-14 21:05:00,149 - __main__ - INFO - SHAP values type: <class 'numpy.ndarray'>
2026-02-14 21:05:00,149 - __main__ - INFO - SHAP values shape: (500, 50, 2)
2026-02-14 21:05:00,149 - __main__ - INFO - SHAP values calculated.
2026-02-14 21:05:00,149 - __main__ - INFO - Generating global importance plot...
2026-02-14 21:05:00,520 - __main__ - INFO - Generating local explanations for 5 samples...
2026-02-14 21:05:01,100 - __main__ - INFO - Generating dependence plots...
2026-02-14 21:05:01,563 - __main__ - INFO - Calculating SHAP interaction values...
2026-02-14 21:05:26,655 - __main__ - WARNING - Could not calculate interactions: operands could not be broadcast together with shapes (50,50,2,50,2) (50,) 
2026-02-14 21:05:26,656 - __main__ - INFO - Testing single prediction explanation...
2026-02-14 21:05:26,673 - __main__ - INFO - Sample Prediction Explanation: {'failure_probability': 0.99, 'top_drivers': [{'feature': 's_4_rolling_mean_7', 'value': 1.3956277979199496, 'shap': np.float64(0.08703167060618897)}, {'feature': 's_17_rolling_mean_7', 'value': 1.6219257000903369, 'shap': np.float64(0.07255293177627241)}, {'feature': 's_2_rolling_mean_7', 'value': 1.3263252170478472, 'shap': np.float64(0.06156856139539706)}, {'feature': 's_3_rolling_mean_7', 'value': 1.111580260305058, 'shap': np.float64(0.053168714455639976)}, {'feature': 's_2_rolling_max_14', 'value': 2.2749774599482206, 'shap': np.float64(0.047639335549624635)}]}
2026-02-14 21:05:26,673 - __main__ - INFO - Interpretation complete.
